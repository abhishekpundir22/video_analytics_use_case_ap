{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2842a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install imutilsa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2f71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c568edb8",
   "metadata": {},
   "source": [
    "# HOG + SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7eea02",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25948/2215122556.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# in the Image that has a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# pedestrians inside it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         (regions, _) = hog.detectMultiScale(image,\n\u001b[0m\u001b[0;32m     22\u001b[0m                                             \u001b[0mwinStride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                                             \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    " \n",
    "# Initializing the HOG person\n",
    "# detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    " \n",
    "cap = cv2.VideoCapture('data/vid.mov')\n",
    " \n",
    "while cap.isOpened():\n",
    "    # Reading the video stream\n",
    "    ret, image = cap.read()\n",
    "    if ret:\n",
    "        image = imutils.resize(image, \n",
    "                               width=min(400, image.shape[1]))\n",
    " \n",
    "        # Detecting all the regions \n",
    "        # in the Image that has a \n",
    "        # pedestrians inside it\n",
    "        (regions, _) = hog.detectMultiScale(image,\n",
    "                                            winStride=(4, 4),\n",
    "                                            padding=(4, 4),\n",
    "                                            scale=1.05)\n",
    " \n",
    "        # Drawing the regions in the \n",
    "        # Image\n",
    "        for (x, y, w, h) in regions:\n",
    "            cv2.rectangle(image, (x, y),\n",
    "                          (x + w, y + h), \n",
    "                          (0, 0, 255), 2)\n",
    " \n",
    "        # Showing the output Image\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c355f8",
   "metadata": {},
   "source": [
    "Limitations of HOG+SVM:\n",
    "\n",
    "Works best for upright, full-body people with clear backgrounds\n",
    "\n",
    "Very sensitive to occlusion, pose, lighting, and scale changes\n",
    "\n",
    "Has trouble with small, partially visible, or side-view pedestrians\n",
    "\n",
    "Not robust for crowded or low-resolution frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6a138",
   "metadata": {},
   "source": [
    "# Applying state of art pretrained YOLO11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e805085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLOv4 weights and config\n",
    "net = cv2.dnn.readNet(\"yolov4-tiny.weights\", \"yolov4-tiny.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "out_layer_idxs = net.getUnconnectedOutLayers().flatten()\n",
    "output_layers = [layer_names[i - 1] for i in out_layer_idxs]\n",
    "\n",
    "cap = cv2.VideoCapture('data/retail-store.mp4')\n",
    "\n",
    "scale_factor = 0.5  # Change to 0.3, 0.4, etc., as needed\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    height, width = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Parse results and draw bounding boxes\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if class_id == 0 and confidence > 0.5:  # 'person' class\n",
    "                center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Resize frame for display\n",
    "    display_frame = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor)\n",
    "    cv2.imshow(\"YOLO Human Detection\", display_frame)\n",
    "    key = cv2.waitKey(25)\n",
    "    # Exit if 'q' is pressed or window is closed\n",
    "    if key & 0xFF == ord('q') or cv2.getWindowProperty(\"YOLO Human Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde8ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59e4627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting YOLOv4 Store Heatmap Processing...\n",
      "Loading YOLOv4 network...\n",
      "Retrieving output layer names...\n",
      "Output layers: ['yolo_139', 'yolo_150', 'yolo_161']\n",
      "Opening video source: data/retail-store.mp4\n",
      "Reading first frame to get frame size...\n",
      "Frame size: 1270x720\n",
      "Starting frame processing loop...\n",
      "Processing frame 30...\n",
      "Processing frame 60...\n",
      "Processing frame 90...\n",
      "Processing frame 120...\n",
      "Processing frame 150...\n",
      "Processing frame 180...\n",
      "Processing frame 210...\n",
      "Processing frame 240...\n",
      "Processing frame 270...\n",
      "Processing frame 300...\n",
      "Processing frame 330...\n",
      "Processing frame 360...\n",
      "Processing frame 390...\n",
      "Processing frame 420...\n",
      "Processing frame 450...\n",
      "Processing frame 480...\n",
      "Processing frame 510...\n",
      "Processing frame 540...\n",
      "Processing frame 570...\n",
      "Processing frame 600...\n",
      "Processing frame 630...\n",
      "Processing frame 660...\n",
      "Processing frame 690...\n",
      "Processing frame 720...\n",
      "Processing frame 750...\n",
      "Processing frame 780...\n",
      "Processing frame 810...\n",
      "Processing frame 840...\n",
      "Processing frame 870...\n",
      "Processing frame 900...\n",
      "Processing frame 930...\n",
      "Processing frame 960...\n",
      "Processing frame 990...\n",
      "Processing frame 1020...\n",
      "Processing frame 1050...\n",
      "Processing frame 1080...\n",
      "Processing frame 1110...\n",
      "Processing frame 1140...\n",
      "Processing frame 1170...\n",
      "Processing frame 1200...\n",
      "Processing frame 1230...\n",
      "Processing frame 1260...\n",
      "End of video stream or cannot fetch frame.\n",
      "Processed total 1282 frames (with skipping).\n",
      "Normalizing and visualizing heatmap...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Starting YOLOv4 Store Heatmap Processing...\")\n",
    "\n",
    "# Load YOLOv4 network\n",
    "print(\"Loading YOLOv4 network...\")\n",
    "net = cv2.dnn.readNet('yolov4.weights', 'yolov4.cfg')\n",
    "\n",
    "# Enable GPU if available and OpenCV compiled with CUDA (optional)\n",
    "# net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Get output layer names safely (fix for OpenCV versions)\n",
    "print(\"Retrieving output layer names...\")\n",
    "layer_names = net.getLayerNames()\n",
    "unconnected_layers = net.getUnconnectedOutLayers()\n",
    "if isinstance(unconnected_layers, np.ndarray):\n",
    "    output_layers = [layer_names[i - 1] for i in unconnected_layers.flatten()]\n",
    "else:\n",
    "    output_layers = [layer_names[i - 1] for i in unconnected_layers]\n",
    "print(\"Output layers:\", output_layers)\n",
    "\n",
    "# Person class ID\n",
    "PERSON_CLASS_ID = 0\n",
    "\n",
    "# Open video file or camera stream\n",
    "video_path = 'data/retail-store.mp4'\n",
    "print(f\"Opening video source: {video_path}\")\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video source.\")\n",
    "    exit()\n",
    "\n",
    "# Read first frame to get size\n",
    "print(\"Reading first frame to get frame size...\")\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Could not read first frame from video.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "frame_height, frame_width = frame.shape[:2]\n",
    "print(f\"Frame size: {frame_width}x{frame_height}\")\n",
    "\n",
    "# Create heatmap accumulator\n",
    "heatmap = np.zeros((frame_height, frame_width), dtype=np.float32)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "print(\"Starting frame processing loop...\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream or cannot fetch frame.\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Skip frames for faster processing (process every 3rd frame)\n",
    "    if frame_count % 3 != 0:\n",
    "        continue\n",
    "\n",
    "    if frame_count % 10 == 0:\n",
    "        print(f\"Processing frame {frame_count}...\")\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Prepare input blob with reduced size 320x320 for faster inference\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (320, 320), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Forward pass\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Parse detections\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if class_id == PERSON_CLASS_ID and confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                heatmap[center_y, center_x] += 1\n",
    "\n",
    "print(f\"Processed total {frame_count} frames (with skipping).\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Normalizing and visualizing heatmap...\")\n",
    "# Normalize and convert heatmap for visualization\n",
    "heatmap_norm = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "heatmap_uint8 = np.uint8(heatmap_norm)\n",
    "colored_heatmap = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
    "\n",
    "plt.imshow(colored_heatmap)\n",
    "plt.title('Store Foot Traffic Heatmap')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a52ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df095ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec3e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd261219",
   "metadata": {},
   "source": [
    "# Applying Yolo11 by Ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335adf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.179-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "argilla 1.7.0 requires numpy<1.24.0, but you have numpy 2.0.2 which is incompatible.\n",
      "pandas-profiling 3.1.0 requires joblib~=1.0.1, but you have joblib 1.4.2 which is incompatible."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (2.26.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.0+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (0.17.0+cu121)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (5.8.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.5.2)\n",
      "Requirement already satisfied: six in c:\\users\\91701\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.21.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2021.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\91701\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: sympy in c:\\users\\91701\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.9)\n",
      "Requirement already satisfied: networkx in c:\\users\\91701\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91701\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91701\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\91701\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.2.1)\n",
      "Downloading ultralytics-8.3.179-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 1.0/1.0 MB 8.4 MB/s  0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, tqdm, ultralytics-thop, ultralytics\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.3\n",
      "    Uninstalling tqdm-4.62.3:\n",
      "      Successfully uninstalled tqdm-4.62.3\n",
      "\n",
      "Successfully installed py-cpuinfo-9.0.0 tqdm-4.67.1 ultralytics-8.3.179 ultralytics-thop-2.0.15\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56a6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n.pt')  # automatically downloads YOLO11n model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3da62b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10536/3982010446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# YOLOv11 expects BGR images directly from OpenCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# class 0 = 'person' in COCO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Draw bounding boxes for detected people\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;33m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"set_prompts\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# for SAM-type models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     def track(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# merge list of Result into one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m                 \u001b[1;31m# Preprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim0s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;31m# Inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self, im)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# BHWC to BCHW, (n, 3, h, w)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# contiguous\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('data/vid.mov')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLOv11 expects BGR images directly from OpenCV\n",
    "    results = model(frame, classes=[0])  # class 0 = 'person' in COCO\n",
    "\n",
    "    # Draw bounding boxes for detected people\n",
    "    annotated_frame = results.plot()\n",
    "\n",
    "    cv2.imshow('YOLO 11 Human Detection', annotated_frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('q') or cv2.getWindowProperty(\"YOLO 11 Human Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f51a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\91701\\anaconda3\\lib\\site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "794f6f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d96625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
